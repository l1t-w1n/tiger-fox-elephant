{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "from models.baseline.baseline_cnn import AnimalDataset\n",
    "from config.config import Config\n",
    "from utils.helper_functions import create_X_y\n",
    "from utils.visualization import plot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCNN(nn.Module):\n",
    "    \"\"\"CNN architecture for binary classification\"\"\"\n",
    "    def __init__(self):\n",
    "        super(BinaryCNN, self).__init__()\n",
    "        \n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Calculate the size of flattened features\n",
    "        flattened_size = 16 * (Config.IMG_SIZE//2) * (Config.IMG_SIZE//2)\n",
    "        \n",
    "        # Fully connected layers with single output for binary classification\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"Training function for binary classification\"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_animal_classifier(X, y, animal_classes):\n",
    "    \"\"\"Function to train a binary classifier for a specific animal\"\"\"\n",
    "    device = torch.device(Config.device)\n",
    "    \n",
    "    # Print dataset information\n",
    "    print(f\"Training classifier for {animal_classes[0]} vs {animal_classes[1]}\")\n",
    "    print(f\"Dataset shape - X: {X.shape}, y: {y.shape}\")\n",
    "    print(f\"Number of samples: {X.shape[0]}\")\n",
    "    print(f\"Image size: {X[0].shape}\")\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    train_size = int(0.8 * len(X))\n",
    "    indices = np.random.permutation(len(X))\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "    \n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_val, y_val = X[val_indices], y[val_indices]\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_dataset = AnimalDataset(X_train, y_train)\n",
    "    val_dataset = AnimalDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = BinaryCNN().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train the model\n",
    "    history = train_binary_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=50,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define the classes\n",
    "    tiger = ['tiger', 'Tiger_negative_class']\n",
    "    elephant = ['elephant', 'Elephant_negative_class']\n",
    "    fox = ['fox', 'Fox_negative_class']\n",
    "    my_classes = [tiger, elephant, fox]\n",
    "    \n",
    "    # Dictionary to store models and their histories\n",
    "    models = {}\n",
    "    \n",
    "    # Train a classifier for each animal\n",
    "    for animal_class in my_classes:\n",
    "        print(f\"\\nProcessing {animal_class[0]} classification...\")\n",
    "        X, y = create_X_y(animal_class)\n",
    "        plot_examples(X, y)\n",
    "        model, history = train_animal_classifier(X, y, animal_class)\n",
    "        models[animal_class[0]] = (model, history)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history[0], label='Train Loss')\n",
    "        plt.plot(history[1], label='Val Loss')\n",
    "        plt.title(f'{animal_class[0]} - Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history[2], label='Train Acc')\n",
    "        plt.plot(history[3], label='Val Acc')\n",
    "        plt.title(f'{animal_class[0]} - Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" models = main() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from utils.helper_functions import save_model\n",
    "for animal, (model, history) in models.items():\n",
    "    save_model(model, history, f\"{animal}_baseline\")\n",
    "    print(f\"Model for {animal}_baseline saved successfully!\") \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper_functions import load_model, evaluate_model\n",
    "from utils.visualization import plot_model_performance, visualize_misclassified,plot_all_examples\n",
    "tiger_model, tiger_history = load_model(BinaryCNN, 'tiger_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiger = ['Tiger_negative _class_for_test', 'tiger_for_test']\n",
    "X_test, y_test = create_X_y(tiger)\n",
    "#print(y_test),\n",
    "\n",
    "#plot_all_examples(X_test, y_test)\n",
    "\n",
    "test_dataset = AnimalDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Plot performance metrics\n",
    "plot_model_performance(tiger_model, test_loader, \"tiger\", Config.device)\n",
    "visualize_misclassified(tiger_model, test_loader, \"tiger\", Config.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_model, fox_history = load_model(BinaryCNN, 'fox_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox = ['Fox_negative_class_for_test', 'fox_for_test']\n",
    "X_test, y_test = create_X_y(fox)\n",
    "print(y_test),\n",
    "\n",
    "#plot_all_examples(X_test, y_test)\n",
    "\n",
    "test_dataset = AnimalDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Plot performance metrics\n",
    "plot_model_performance(fox_model, test_loader, \"fox\", Config.device)\n",
    "visualize_misclassified(fox_model, test_loader, \"fox\", Config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elephant_model, elephant_history = load_model(BinaryCNN, 'elephant_baseline')\n",
    "elephant = ['Elephant_negative_class_for_test', 'elephant_for_test']\n",
    "X_test, y_test = create_X_y(elephant)\n",
    "print(y_test),\n",
    "\n",
    "#plot_all_examples(X_test, y_test)\n",
    "\n",
    "test_dataset = AnimalDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# Plot performance metrics\n",
    "plot_model_performance(elephant_model, test_loader, \"elephant\", Config.device)\n",
    "visualize_misclassified(elephant_model, test_loader, \"elephant\", Config.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
